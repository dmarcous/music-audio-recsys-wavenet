# Abstract #

Enhancements to deep content-based music recommendation

Several advancements have been made in this area, including a
method which predicts latent factors from raw audio signals using
convolutional neural networks. Its input consist of embeddings of
the audio signals, generated by commonly used audio
representation methods.
In the field of neural networks and raw audio signals, a recent post
by DeepMind presented a deep generative model of raw audio
waveforms. This model includes neural network layers which can
be used to compute audio signal embeddings.
We present a combination of the two methods mentioned above â€“
a neural network which predicts latent factors from raw audio
signals, based on pre-trained layers which compute audio signal
embeddings. 

This work presents a novel approach for audio
content based music recommendation using song embedding
instead of audio data processing representations, with the notion
of the embedding using the entirety of the audio file, while
preprocessing techniques lose data when capturing only specific
signals such as frequency over time.

Testing shows that this algorithm performs roughly
the same on MAP and AUC as the latest state of the art (referred to as the original
algorithm), but with 1/38 the size of audio data representation.
This fact has significant implications for storage and memory
requirements, as well as reduced training times

## Authors ##

Daniel Marcous 
dmarcous@gmail.com

Yotam Sandbank
yotamsandbank@gmail.com

