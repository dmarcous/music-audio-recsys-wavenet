{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import feather\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from ml_metrics.average_precision import apk\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read song factors\n",
    "with open('data/song_latent_factors.pkl', 'rb') as f:\n",
    "    song_factors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read relevant songs from embeddings and from spectrograms, and intersect them\n",
    "\n",
    "rel_songs_from_embedding = feather.read_dataframe('data/embedding_songs_list.feather')\n",
    "rel_songs_from_embedding = set([r_s.decode() for r_s in rel_songs_from_embedding['0']])\n",
    "\n",
    "rel_songs_from_spectrograms = feather.read_dataframe('data/spectrogram_songs_list.feather')\n",
    "rel_songs_from_spectrograms = set([r_s.decode() for r_s in rel_songs_from_spectrograms ['0']])\n",
    "\n",
    "rel_songs = rel_songs_from_embedding.intersection(rel_songs_from_spectrograms)\n",
    "rel_songs = [s for s in rel_songs if s in song_factors]\n",
    "\n",
    "del rel_songs_from_embedding, rel_songs_from_spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_songs,test_songs = train_test_split(rel_songs, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save train/test songs\n",
    "labels = list(np.repeat('train', len(train_songs))) + list(np.repeat('test', len(test_songs)))\n",
    "songs_train_test = pd.DataFrame({'song':train_songs+test_songs, 'label':labels})\n",
    "feather.write_dataframe(songs_train_test, 'data/songs_train_test.feather')\n",
    "\n",
    "del songs_train_test, train_songs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read user factors\n",
    "with open('data/user_latent_factors.pkl', 'rb') as f:\n",
    "    user_factors = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Keep only relevant song factors\n",
    "song_factors = pd.DataFrame.from_dict({s:[song_factors[s]] for s in test_songs if s in song_factors}, orient='index')\n",
    "song_factors.columns = ['factor']\n",
    "song_factors.index.name = 'song'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dictionary of user:songs (only for test songs)\n",
    "user_songs = {user:set() for user in user_factors.keys()}\n",
    "with open('./data/train_triplets.txt') as f:\n",
    "    for line in f:\n",
    "        s = line.strip().split('\\t')\n",
    "        user = users[s[0]]\n",
    "        song = songs[s[1]]\n",
    "        if song in song_factors.index:\n",
    "            user_songs[user].add(song)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "k = 500\n",
    "def evaluate(user):\n",
    "    scores = (song_factors['factor'] * user_factors[user]).apply(sum).sort_values(ascending=False)\n",
    "    user_apk = apk(list(scores.index[:k]), user_songs[user])\n",
    "    user_auc = roc_auc_score([s in user_songs[user] for s in scores.index], scores.values)\n",
    "    return (user_apk,user_auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Evaluate on all users\n",
    "scores = [x for x in zip(*[evaluate(user) for user in user_songs.keys()])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean average percision at 500: 0.6648\n",
      "Mean area under ROC: 0.9104\n"
     ]
    }
   ],
   "source": [
    "print('Mean average percision at {0}: {1:.4f}'.format(k, np.mean(scores[0])))\n",
    "print('Mean area under ROC: {0:.4f}'.format(np.mean(scores[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
